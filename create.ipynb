{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a90bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "torch.serialization.add_safe_globals([torch_geometric.data.data.DataEdgeAttr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810e143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QM9GraphDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class to convert SMILES from QM9 CSV to PyTorch Geometric graphs\n",
    "    with BBBP labels\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path: str, root: str = None, transform=None, pre_transform=None):\n",
    "        self.csv_path = csv_path\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        # Filter out invalid SMILES\n",
    "        self.df = self.df.dropna(subset=['smiles'])\n",
    "        # Create processed graphs directory\n",
    "        self.processed_dir_path = os.path.join(root or '.', 'processed')\n",
    "        os.makedirs(self.processed_dir_path, exist_ok=True)\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        # Process data if not already processed\n",
    "        if not self._check_processed():\n",
    "            self.process()\n",
    "\n",
    "    def _check_processed(self) -> bool:\n",
    "        \"\"\"Check if processed files exist.\"\"\"\n",
    "        return len([f for f in os.listdir(self.processed_dir_path) if f.endswith('.pt')]) > 0\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        return [self.csv_path]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> List[str]:\n",
    "        return [f'data_{i}.pt' for i in range(len(self.df))]\n",
    "\n",
    "    def download(self):\n",
    "        # Data is already provided as CSV\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"Convert SMILES to graphs and save processed data.\"\"\"\n",
    "        print(f\"Processing {len(self.df)} molecules...\")\n",
    "        idx = 0\n",
    "        failed = 0\n",
    "\n",
    "        for i, row in self.df.iterrows():\n",
    "            smiles = row['smiles']\n",
    "            data = self.smiles_to_graph(\n",
    "                smiles,\n",
    "                bbbp_label=row.get('bbbp', 0.0)\n",
    "            )\n",
    "            if data is not None:\n",
    "                if self.pre_transform:\n",
    "                    data = self.pre_transform(data)\n",
    "                torch.save(data, os.path.join(self.processed_dir_path, f'data_{idx}.pt'))\n",
    "                idx += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "\n",
    "        print(f\"Successfully processed {idx} molecules, failed: {failed}\")\n",
    "        self._indices = list(range(idx))\n",
    "\n",
    "    def len(self) -> int:\n",
    "        return len([f for f in os.listdir(self.processed_dir_path) if f.endswith('.pt')])\n",
    "\n",
    "    def get(self, idx: int) -> Data:\n",
    "        path = os.path.join(self.processed_dir_path, f'data_{idx}.pt')\n",
    "        # Option 1: Use weights_only=False (safe since we created these files)\n",
    "        return torch.load(path, weights_only=False)\n",
    "        \n",
    "        # Option 2: Use safe_globals context manager (more secure but verbose)\n",
    "        # from torch_geometric.data.data import DataEdgeAttr\n",
    "        # with torch.serialization.safe_globals([DataEdgeAttr, Data]):\n",
    "        #     return torch.load(path, weights_only=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_atom_features(atom) -> List[float]:\n",
    "        \"\"\"Extract atom features for graph nodes.\"\"\"\n",
    "        features = []\n",
    "        atomic_nums = [1, 6, 7, 8, 9, 15, 16, 17, 35, 53]\n",
    "        features += [1 if atom.GetAtomicNum() == num else 0 for num in atomic_nums]\n",
    "        degrees = [0, 1, 2, 3, 4, 5]\n",
    "        features += [1 if atom.GetDegree() == d else 0 for d in degrees]\n",
    "        charges = [-2, -1, 0, 1, 2]\n",
    "        features += [1 if atom.GetFormalCharge() == c else 0 for c in charges]\n",
    "        hybridizations = [\n",
    "            Chem.HybridizationType.S, Chem.HybridizationType.SP,\n",
    "            Chem.HybridizationType.SP2, Chem.HybridizationType.SP3,\n",
    "            Chem.HybridizationType.SP3D, Chem.HybridizationType.SP3D2\n",
    "        ]\n",
    "        features += [1 if atom.GetHybridization() == hyb else 0 for hyb in hybridizations]\n",
    "        features.append(1 if atom.GetIsAromatic() else 0)\n",
    "        features.append(1 if atom.IsInRing() else 0)\n",
    "        return features\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bond_features(bond) -> List[float]:\n",
    "        \"\"\"Extract bond features for graph edges.\"\"\"\n",
    "        features = []\n",
    "        bond_types = [\n",
    "            Chem.BondType.SINGLE, Chem.BondType.DOUBLE,\n",
    "            Chem.BondType.TRIPLE, Chem.BondType.AROMATIC\n",
    "        ]\n",
    "        features += [1 if bond.GetBondType() == bt else 0 for bt in bond_types]\n",
    "        features.append(1 if bond.GetIsConjugated() else 0)\n",
    "        features.append(1 if bond.IsInRing() else 0)\n",
    "        return features\n",
    "\n",
    "    def smiles_to_graph(self, smiles: str, bbbp_label: float) -> Optional[Data]:\n",
    "        \"\"\"Convert a SMILES string to a PyG Data object.\"\"\"\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None: return None\n",
    "        mol = Chem.AddHs(mol)\n",
    "\n",
    "        # Node features\n",
    "        atom_feats = [self.get_atom_features(atom) for atom in mol.GetAtoms()]\n",
    "        if not atom_feats:\n",
    "            return None\n",
    "        x = torch.tensor(atom_feats, dtype=torch.float)\n",
    "\n",
    "        # Edge indices and features\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            feats = self.get_bond_features(bond)\n",
    "            edge_index += [[i, j], [j, i]]\n",
    "            edge_attr += [feats, feats]\n",
    "\n",
    "        if edge_index:\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "            edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "        else:\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "            edge_attr = torch.empty((0, 6), dtype=torch.float)\n",
    "\n",
    "        # Graph-level label (BBBP permeability score)\n",
    "        y = torch.tensor([bbbp_label], dtype=torch.float)\n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, smiles=smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de49d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(dataset, batch_size=32, train_ratio=0.8, val_ratio=0.1, random_state=67):\n",
    "    \"\"\"Split dataset and return DataLoaders for train, val, and test.\"\"\"\n",
    "    indices = list(range(len(dataset)))\n",
    "    train_idx, temp_idx = train_test_split(indices, test_size=1-train_ratio, random_state=random_state)\n",
    "    val_ratio_adj = val_ratio / (1-train_ratio)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=1-val_ratio_adj, random_state=random_state)\n",
    "    train_ds = [dataset[i] for i in train_idx]\n",
    "    val_ds   = [dataset[i] for i in val_idx]\n",
    "    test_ds  = [dataset[i] for i in test_idx]\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "    print(f\"Dataset splits â€” Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d46997eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2142 molecules...\n",
      "Successfully processed 2142 molecules, failed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = QM9GraphDataset(csv_path=\"qm9_bbbp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1710080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample SMILES: CCCC#CC1OC1C\n",
      "Node feature shape: torch.Size([21, 29])\n",
      "Edge index shape: torch.Size([2, 42])\n",
      "Edge attr shape: torch.Size([42, 6])\n",
      "BBBP Label: tensor([0.9496])\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[67]\n",
    "print(\"Sample SMILES:\", sample.smiles)\n",
    "print(\"Node feature shape:\", sample.x.shape)\n",
    "print(\"Edge index shape:\", sample.edge_index.shape)\n",
    "print(\"Edge attr shape:\", sample.edge_attr.shape)\n",
    "print(\"BBBP Label:\", sample.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bdab50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits â€” Train: 1713, Val: 214, Test: 215\n",
      "Batch x shape: torch.Size([64, 29])\n",
      "Batch edge_index shape: torch.Size([2, 132])\n",
      "Batch y shape: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = create_data_loaders(dataset, batch_size=4)\n",
    "for batch in train_loader:\n",
    "    print(\"Batch x shape:\", batch.x.shape)\n",
    "    print(\"Batch edge_index shape:\", batch.edge_index.shape)\n",
    "    print(\"Batch y shape:\", batch.y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610a01b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
