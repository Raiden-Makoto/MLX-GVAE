{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78d5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "501cf556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GINEConv, global_add_pool\n",
    "import numpy as np\n",
    "import rdkit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cad70d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d21c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3e0f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QM9(root='./QM9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18dd227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "g = torch.Generator().manual_seed(67)\n",
    "sample_size = int(0.67 * len(dataset))\n",
    "dataset_67, _ = random_split(dataset, [sample_size, len(dataset) - sample_size], generator=g)\n",
    "\n",
    "num_train = int(0.8 * len(dataset_67))\n",
    "num_val = int(0.1 * len(dataset_67))\n",
    "train_set, val_set, test_set = random_split(\n",
    "    dataset_67, [num_train, num_val, len(dataset_67) - num_train - num_val], generator=g\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78122806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 70124\n",
      "Validation set size: 8765\n",
      "Test set size: 8767\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_set,   batch_size=64)\n",
    "test_loader  = DataLoader(test_set,  batch_size=64)\n",
    "print(\"Train set size:\", len(train_set))\n",
    "print(\"Validation set size:\", len(val_set))\n",
    "print(\"Test set size:\", len(test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d650bd5f",
   "metadata": {},
   "source": [
    "## Encoder Architecture\n",
    "The **Encoder** consists of:\n",
    "- Message-passing layers (e.g., GCNConv, GINEConv) to compute node embeddings.\n",
    "- Global readout (e.g., `global_add_pool`) to obtain graph representation $h$\n",
    "- Two separate MLPs mapping $h$ to latent mean $\\mu$ and log-variance log $\\sigma^2$\n",
    "\n",
    "**Reparameterization**    \n",
    "Sample $z = \\mu + \\exp(\\frac{1}{2} \\sigma^2) \\odot \\varepsilon$ where $\\varepsilon \\sim N(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf926026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_add_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc6c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim, latent_dim, edge_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = GINEConv(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(in_channels, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            ),\n",
    "            edge_dim=edge_dim\n",
    "        )\n",
    "        self.conv2 = GINEConv(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            ),\n",
    "            edge_dim=edge_dim\n",
    "        )\n",
    "        self.readout = global_add_pool\n",
    "        self.lin_mu  = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.lin_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = torch.relu(x)\n",
    "        h = self.readout(x, batch)\n",
    "        mu = self.lin_mu(h)\n",
    "        logvar = self.lin_logvar(h)\n",
    "        return mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "868d0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83c2de",
   "metadata": {},
   "source": [
    "## Decoder Architecture\n",
    "Condition on $z$ to reconstruct adjacency and node features. For example:\n",
    "- Edge-wise MLP: For each potential node pair, predict bond existence/type.\n",
    "- Autoregressive (e.g., graph sequential decoding).\n",
    "- Graph deconvolution layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b45145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim,\n",
    "        hidden_dim,\n",
    "        num_node_types,\n",
    "        num_edge_types,\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_node_types),\n",
    "        )\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_edge_types),\n",
    "        )\n",
    "\n",
    "    def forward(self, z, batch, edge_index=None):\n",
    "        # z: [num_graphs_in_batch, latent_dim]\n",
    "        # batch: [num_nodes] mapping each node to its graph index\n",
    "        # Broadcast z to node-level using batch\n",
    "        z_nodes = z[batch]  # [num_nodes, latent_dim]\n",
    "        node_logits = self.node_mlp(z_nodes)\n",
    "\n",
    "        edge_logits = None\n",
    "        if edge_index is not None:\n",
    "            src, dst = edge_index\n",
    "            edge_inputs = torch.cat([z_nodes[src], z_nodes[dst]], dim=-1)\n",
    "            edge_logits = self.edge_mlp(edge_inputs)\n",
    "\n",
    "        return node_logits, edge_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f21cb81",
   "metadata": {},
   "source": [
    "## VAE Setup and Loss\n",
    "**Loss**: Reconstruction Loss: Cross-entropy for discrete features (atom types, bond types)    \n",
    "**KL Divergence**: $\\text{KL} = -\\frac{1}{2}\\sum_{i=1}^d(1 + \\log \\sigma_i^2 - \\mu_i^2 - \\sigma_i^2)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f3ecdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(node_logits, true_node_labels, edge_logits, true_edge_labels, mu, logvar):\n",
    "    recon_node = nn.CrossEntropyLoss()(node_logits, true_node_labels)\n",
    "    recon_edge = nn.CrossEntropyLoss()(edge_logits, true_edge_labels)\n",
    "    kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_node + recon_edge + 1e-4 * kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "032e7af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (conv1): GINEConv(nn=Sequential(\n",
      "    (0): Linear(in_features=11, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  ))\n",
      "  (conv2): GINEConv(nn=Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  ))\n",
      "  (lin_mu): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (lin_logvar): Linear(in_features=128, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "E = Encoder(\n",
    "    in_channels=dataset.num_node_features,\n",
    "    hidden_dim=128,\n",
    "    latent_dim=64,\n",
    "    edge_dim=dataset.num_edge_features\n",
    ")\n",
    "E.to(device)\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a6c6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (node_mlp): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      "  (edge_mlp): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "D = Decoder(\n",
    "    latent_dim=64,\n",
    "    hidden_dim=128,\n",
    "    num_node_types=5, # C, N, O, F, H\n",
    "    num_edge_types=4 # single, double, triple, aromatic\n",
    ")\n",
    "D.to(device)\n",
    "print(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a07acb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(list(E.parameters()) + list(D.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f8bf6",
   "metadata": {},
   "source": [
    "## Model Training (10 Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b66f3da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Loss: 0.2327\n",
      "Epoch 002, Loss: 0.2135\n",
      "Epoch 003, Loss: 0.2133\n",
      "Epoch 004, Loss: 0.2131\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m D.train()\n\u001b[32m      4\u001b[39m total_loss = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Move batch to the selected device to avoid CPU/MPS mismatch\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/QVAE/qvae/lib/python3.11/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/QVAE/qvae/lib/python3.11/site-packages/torch/utils/data/dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/QVAE/qvae/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/QVAE/qvae/lib/python3.11/site-packages/torch/utils/data/dataset.py:414\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[_T_co]:\n\u001b[32m    411\u001b[39m     \u001b[38;5;66;03m# add batched sampling support when parent dataset supports it.\u001b[39;00m\n\u001b[32m    412\u001b[39m     \u001b[38;5;66;03m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[39;00m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    416\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.dataset[\u001b[38;5;28mself\u001b[39m.indices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/QVAE/qvae/lib/python3.11/site-packages/torch/utils/data/dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/QVAE/qvae/lib/python3.11/site-packages/torch/utils/data/dataset.py:416\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/QVAE/qvae/lib/python3.11/site-packages/torch_geometric/data/dataset.py:291\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[33;03mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03mpresent).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    285\u001b[39m \u001b[33;03mbool, will return a subset of the dataset at the specified indices.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np.integer))\n\u001b[32m    288\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx.dim() == \u001b[32m0\u001b[39m)\n\u001b[32m    289\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np.ndarray) \u001b[38;5;129;01mand\u001b[39;00m np.isscalar(idx))):\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     data = data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform(data)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/QVAE/qvae/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:109\u001b[39m, in \u001b[36mInMemoryDataset.get\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_list = \u001b[38;5;28mself\u001b[39m.len() * [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_list[idx] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m data = separate(\n\u001b[32m    112\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mself\u001b[39m._data.\u001b[34m__class__\u001b[39m,\n\u001b[32m    113\u001b[39m     batch=\u001b[38;5;28mself\u001b[39m._data,\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m     decrement=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    117\u001b[39m )\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m._data_list[idx] = copy.copy(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/copy.py:84\u001b[39m, in \u001b[36mcopy\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     82\u001b[39m copier = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__copy__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m reductor = dispatch_table.get(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reductor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/QVAE/qvae/lib/python3.11/site-packages/torch_geometric/data/data.py:590\u001b[39m, in \u001b[36mData.__copy__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m.items():\n\u001b[32m    589\u001b[39m     out.\u001b[34m__dict__\u001b[39m[key] = value\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m out.\u001b[34m__dict__\u001b[39m[\u001b[33m'\u001b[39m\u001b[33m_store\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_store\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m out._store._parent = out\n\u001b[32m    592\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/copy.py:84\u001b[39m, in \u001b[36mcopy\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     82\u001b[39m copier = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__copy__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m reductor = dispatch_table.get(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reductor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/QVAE/qvae/lib/python3.11/site-packages/torch_geometric/data/storage.py:140\u001b[39m, in \u001b[36mBaseStorage.__copy__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key != \u001b[33m'\u001b[39m\u001b[33m_cached_attr\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    139\u001b[39m         out.\u001b[34m__dict__\u001b[39m[key] = value\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m out._mapping = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/copy.py:76\u001b[39m, in \u001b[36mcopy\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     74\u001b[39m copier = _copy_dispatch.get(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m copier(x)\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n\u001b[32m     79\u001b[39m     \u001b[38;5;66;03m# treat it as a regular class:\u001b[39;00m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _copy_immutable(x)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    E.train()\n",
    "    D.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        # Move batch to the selected device to avoid CPU/MPS mismatch\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        mu, logvar = E(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        \n",
    "        # Decoder now expects per-node broadcast via batch and optional edge_index\n",
    "        node_logits, edge_logits = D(z, data.batch, data.edge_index)\n",
    "\n",
    "        # Targets aligned to per-node and per-edge predictions\n",
    "        node_targets = data.x.argmax(dim=1)\n",
    "        edge_targets = data.edge_attr.argmax(dim=1)\n",
    "\n",
    "        loss = vae_loss(\n",
    "            node_logits, node_targets,\n",
    "            edge_logits, edge_targets,\n",
    "            mu, logvar\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch:03d}, Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424f098",
   "metadata": {},
   "source": [
    "Ok this uses too much memory and training is about done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2708c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = {\n",
    "    \"epoch\": epoch,\n",
    "    \"encoder\": E.state_dict(),\n",
    "    \"decoder\": D.state_dict(),\n",
    "    \"optimizer\": optimizer.state_dict(),\n",
    "    \"train_args\": {\"lr\": 1e-3, \"batch_size\": 64},\n",
    "}\n",
    "torch.save(ckpt, \"checkpoints/qvae_epoch_{:03d}.pt\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8244eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ckpt, \"checkpoints/qvae_best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8cdeb2",
   "metadata": {},
   "source": [
    "## Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03812d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"checkpoints/qvae_best.pt\", map_location=device)\n",
    "E.load_state_dict(ckpt[\"encoder\"])\n",
    "D.load_state_dict(ckpt[\"decoder\"])\n",
    "optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "start_epoch = ckpt.get(\"epoch\", 0) + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
